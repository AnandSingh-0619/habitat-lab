{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20fd9459-8522-471c-8306-e9173a53c2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/asingh3064/miniconda3/envs/habitat/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import git\n",
    "import numpy as np\n",
    "from gym import spaces\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import habitat\n",
    "from habitat.core.logging import logger\n",
    "from habitat.core.registry import registry\n",
    "from habitat.sims.habitat_simulator.actions import HabitatSimActions\n",
    "from habitat.tasks.nav.nav import NavigationTask\n",
    "from habitat_baselines.common.baseline_registry import baseline_registry\n",
    "from habitat_baselines.config.default import get_config as get_baselines_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 21:24:12,175 Initializing dataset RearrangeDataset-v0\n",
      "2024-01-25 21:24:34,594 initializing sim RearrangeSim-v0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config = habitat.get_config(\n",
    "        config_path=\"benchmark/rearrange/pick.yaml\",\n",
    "        overrides=[\n",
    "\n",
    "            \"habitat.environment.iterator_options.shuffle=False\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        env.close()  # type: ignore[has-type]\n",
    "    except NameError:\n",
    "        pass\n",
    "    env = habitat.Env(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from habitat.core.dataset import Dataset, Episode\n",
    "\n",
    "dataset = env._dataset\n",
    "def filter_fn(episode: Episode) -> bool:\n",
    "    return int(episode.episode_id) < 3 \n",
    "\n",
    "\n",
    "filtered_dataset = dataset.filter_episodes(filter_fn)\n",
    "assert len(filtered_dataset.episodes) == 3\n",
    "for ep in filtered_dataset.episodes:\n",
    "        print(ep.info)\n",
    "        assert filter_fn(ep)\n",
    "env._dataset = filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from habitat_sim.utils import viz_utils as vut\n",
    "from habitat.utils.visualizations.utils import (\n",
    "    observations_to_image,\n",
    "    overlay_frame,\n",
    ")\n",
    "from habitat.tasks.rearrange.utils import (\n",
    "    CollisionDetails,\n",
    "    UsesArticulatedAgentInterface,\n",
    "    batch_transform_point,\n",
    "    get_angle_to_pos,\n",
    "    rearrange_logger,\n",
    ")\n",
    "from habitat.tasks.rearrange.rearrange_sim import RearrangeSim\n",
    "observations = env.reset()  # noqa: F841\n",
    "\n",
    "print(\"Agent acting inside environment.\")\n",
    "count_steps = 0\n",
    "# To save the video\n",
    "video_file_path = \"data/example_interact.mp4\"\n",
    "video_writer = vut.get_fast_video_writer(video_file_path, fps=30)\n",
    "\n",
    "while not env.episode_over:\n",
    "    observations = env.step(env.action_space.sample())  # noqa: F841\n",
    "    info = env.get_metrics()\n",
    "    print(info)\n",
    "    # print(observations)\n",
    "    render_obs = observations_to_image(observations, info)\n",
    "    render_obs = overlay_frame(render_obs, info)\n",
    "\n",
    "    video_writer.append_data(render_obs)\n",
    "\n",
    "    count_steps += 1\n",
    "print(\"Episode finished after {} steps.\".format(count_steps))\n",
    "\n",
    "video_writer.close()\n",
    "if vut.is_notebook():\n",
    "    vut.display_video(video_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations.keys()\n",
    "# print(observations[\"ee_pos\"])\n",
    "# print(observations[\"obj_start_sensor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample(\n",
    "    rgb_obs, semantic_obs=np.array([]), depth_obs=np.array([])):  # noqa: B006\n",
    "    from habitat_sim.utils.common import d3_40_colors_rgb\n",
    "\n",
    "    rgb_img = Image.fromarray(rgb_obs, mode=\"RGB\")\n",
    "\n",
    "    arr = [rgb_img]\n",
    "    titles = [\"rgb\"]\n",
    "    if semantic_obs.size != 0:\n",
    "        semantic_img = Image.new(\n",
    "            \"P\", (semantic_obs.shape[1], semantic_obs.shape[0])\n",
    "        )\n",
    "        semantic_img.putpalette(d3_40_colors_rgb.flatten())\n",
    "        semantic_img.putdata((semantic_obs.flatten() % 40).astype(np.uint8))\n",
    "        semantic_img = semantic_img.convert(\"RGBA\")\n",
    "        arr.append(semantic_img)\n",
    "        titles.append(\"semantic\")\n",
    "\n",
    "    if depth_obs.size != 0:\n",
    "        depth_img = Image.fromarray(\n",
    "            (depth_obs / 10 * 255).astype(np.uint8), mode=\"L\"\n",
    "        )\n",
    "        arr.append(depth_img)\n",
    "        titles.append(\"depth\")\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i, data in enumerate(arr):\n",
    "        ax = plt.subplot(1, 3, i + 1)\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(titles[i])\n",
    "        plt.imshow(data)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from gym import spaces\n",
    "# import habitat_baselines.rl.ddppo.policy as pol\n",
    "from habitat_baselines.rl.ddppo.policy import ( \n",
    "    PointNavResNetNet,\n",
    "    PointNavResNetPolicy,\n",
    ")\n",
    "from habitat_baselines.config.default import get_config\n",
    "from typing import Dict, Optional\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "class MyPolicy(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyPolicy, self).__init__()\n",
    "\n",
    "        ACTION_SPACE = spaces.Discrete(4)\n",
    "\n",
    "        OBSERVATION_SPACES = {\n",
    "            \"depth_model\": spaces.Dict(\n",
    "                {\n",
    "                    \"depth\": spaces.Box(\n",
    "                        low=0.0,\n",
    "                        high=1.0,\n",
    "                        shape=(224, 224, 1),\n",
    "                        dtype=np.float32,\n",
    "                    ),\n",
    "                    \"pointgoal_with_gps_compass\": spaces.Box(\n",
    "                        low=-3.4028235e+38,\n",
    "                        high=3.4028235e+38,\n",
    "                        shape=(2,),\n",
    "                        dtype=np.float32,\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "        }\n",
    "        # config = get_config(\n",
    "        #     \"test/config/habitat_baselines/ddppo_pointnav_test.yaml\"\n",
    "        # )\n",
    "        MODELS = {\n",
    "            \"pointnav_weights.pth\": {\n",
    "                \"backbone\": \"resnet18\",\n",
    "                \"observation_space\": OBSERVATION_SPACES[\"depth_model\"],\n",
    "                \"action_space\": ACTION_SPACE,\n",
    "            }}\n",
    "        PTH_GPU_ID: int = 0\n",
    "        self.device = (\n",
    "            torch.device(\"cuda:{}\".format(PTH_GPU_ID))\n",
    "            # if torch.cuda.is_available()\n",
    "            # else torch.device(\"cpu\")\n",
    "        )\n",
    "        model_weights_path = '/home/anand/Downloads/pointnav_weights.pth'  # Replace with the actual path to your model weights file\n",
    "\n",
    "        pretrained_state = torch.load(model_weights_path, map_location=\"cuda:0\")\n",
    "\n",
    "        # self.policy = PointNavResNetPolicy.from_config( config=config,\n",
    "        #                                                 observation_space=OBSERVATION_SPACES[\"depth_model\"], \n",
    "        #                                                 action_space=ACTION_SPACE)\n",
    "        \n",
    "        self.policy= PointNavResNetPolicy(observation_space=OBSERVATION_SPACES[\"depth_model\"], \n",
    "                                                        action_space=ACTION_SPACE,\n",
    "                                                        hidden_size = 512,\n",
    "                                                        num_recurrent_layers = 2,\n",
    "                                                        rnn_type=\"LSTM\")\n",
    "                                        \n",
    "        self.policy.load_state_dict(pretrained_state)\n",
    "        self.rnn_hidden_states: Optional[torch.Tensor] = None\n",
    "        self.not_done_masks: Optional[torch.Tensor] = None\n",
    "        self.prev_actions: Optional[torch.Tensor] = None\n",
    "        # self.policy.to(self.device)\n",
    "        self.hidden_size = 512\n",
    "        self.policy.eval()\n",
    "        self.prev_actions = torch.zeros(\n",
    "            1, 1, dtype=torch.long, device='cuda:0')\n",
    "\n",
    "        self.rnn_hidden_states = torch.zeros(\n",
    "            1,\n",
    "            self.policy.net.num_recurrent_layers,\n",
    "            self.hidden_size,\n",
    "            device=self.device,\n",
    "        )\n",
    "        self.not_done_masks = torch.zeros(\n",
    "            1, 1, device='cuda:0', dtype=torch.bool\n",
    "        )\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, obs):\n",
    "        # Extract observations\n",
    "        depth_image = obs['head_depth']\n",
    "        env.current_episode.info\n",
    "        relative_position = obs[\"obj_start_sensor\"] \n",
    "        # print(relative_position)\n",
    "        rho = np.linalg.norm(relative_position)\n",
    "        theta = np.arctan2(relative_position[1], relative_position[0])\n",
    "        display_sample(obs[\"head_depth\"])\n",
    "\n",
    "        depth_image_tensor = torch.from_numpy(depth_image.transpose(2, 0, 1)).unsqueeze(0).float()  # Transpose to (1, 256, 256)\n",
    "        depth_image_tensor = depth_image_tensor.permute(0, 1, 3, 2)  # Transpose to (1, 256, 256)\n",
    "        # print(depth_image_tensor.size())\n",
    "\n",
    "        # Define the transformation to resize the image\n",
    "        with torch.no_grad():\n",
    "            resized_depth_image_tensor = F.interpolate(depth_image_tensor, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "            # resized_depth_image_tensor /= 5.0       \n",
    "        resized_depth_image_tensor = resized_depth_image_tensor.permute(0,2,3,1)  \n",
    "        # print(resized_depth_image_tensor.size())\n",
    "        device = torch.device(\"cuda:0\")  # Assuming you want to use GPU 0\n",
    "        resized_depth_image_tensor = resized_depth_image_tensor.to(self.device)\n",
    "\n",
    "        self.policy.to(device = 'cuda:0')\n",
    "  \n",
    "        print(resized_depth_image_tensor.device)\n",
    "        print(\"Destination, distance: {:.3f}, theta (radians): {:.2f}\".format(\n",
    "            rho,\n",
    "            theta))\n",
    "\n",
    "        resized_point_goal_tensor = torch.tensor([[rho, theta]], dtype=torch.float32, device='cuda:0')        # Process observations through the policy\n",
    "        action_logits = self.policy.act(\n",
    "            observations={\"depth\": resized_depth_image_tensor, \"pointgoal_with_gps_compass\": resized_point_goal_tensor},\n",
    "            rnn_hidden_states=self.rnn_hidden_states,\n",
    "            prev_actions=self.prev_actions,\n",
    "            masks=self.not_done_masks,\n",
    "            deterministic=False)\n",
    "        self.rnn_hidden_states = action_logits.rnn_hidden_states\n",
    "        # Convert action logits to actions (0: stop, 1: move forward, 2: pivot left, 3: pivot right)\n",
    "        action = torch.argmax(action_logits.actions, dim=1).item()\n",
    "        values = torch.argmax(action_logits.values, dim=1).item()\n",
    "        print(\"Action: \",action)\n",
    "        display_sample(obs[\"head_rgb\"])\n",
    "\n",
    "        return action\n",
    "    \n",
    "\n",
    "\n",
    "pol=MyPolicy()\n",
    "obs= env.reset()\n",
    "action = pol.forward(obs)\n",
    "\n",
    "valid_actions = [\"stop\",\"move_forward\",\"turn_left\", \"turn_right\"]\n",
    "action = valid_actions[action]\n",
    "# print(env.observation_space)\n",
    "interactive_control = False  # @param {type:\"boolean\"}\n",
    "while action != \"stop\":\n",
    "    display_sample(obs[\"head_rgb\"])\n",
    "    obs = env.step(\n",
    "        {\n",
    "            \"action\": action,\n",
    "        }\n",
    "    )\n",
    "    action = pol.forward(obs)\n",
    "    action = valid_actions[action]\n",
    "    print(action)\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
